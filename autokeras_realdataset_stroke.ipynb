{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29454343",
   "metadata": {},
   "source": [
    "<h1>Aprendizaje automático automatizado usando AutoKeras para predecir accidentes cerebrovasculares</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41689ccf",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6edf56",
   "metadata": {},
   "source": [
    "<h3>En este Notebook se va a preparar y ejecutar aprendizaje automático automatizado sobre el <i>dataset</i> 'healthcare-dataset-stroke-data.csv' (https://www.kaggle.com/fedesoriano/stroke-prediction-dataset) para conseguir un modelo capaz de predecir si un paciente con determinadas características médicas sufrirá una isquemia cerebral o si por el contrario no es propenso a ello</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8aa3026",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4682ae81",
   "metadata": {},
   "source": [
    "<h2>1. Importación de librerías y preparación del <i>dataset</i></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd09146",
   "metadata": {},
   "source": [
    "<p>En primer lugar, se importan los paquetes y librerías necesarias para la ejecución del código:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3ed501b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import autokeras as ak\n",
    "import kerastuner as kt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce2f9e2",
   "metadata": {},
   "source": [
    "<p>A continuación, se procede a la lectura de los datos del archivo <i>healthcare-dataset-stroke-data.csv</i>. Para ello, se han visualizado los datos en bruto previamente para conocer qué atributos hay y sus respectivos tipos. Una vez resvisados, se procede a crear el <i>dataframe</i> de Pandas con los tipos de dato correctos y con el contenido del fichero CSV.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17ec014b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>ever_married</th>\n",
       "      <th>work_type</th>\n",
       "      <th>Residence_type</th>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>smoking_status</th>\n",
       "      <th>stroke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9046</td>\n",
       "      <td>Male</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>228.69</td>\n",
       "      <td>36.6</td>\n",
       "      <td>formerly smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51676</td>\n",
       "      <td>Female</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>Rural</td>\n",
       "      <td>202.21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31112</td>\n",
       "      <td>Male</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Rural</td>\n",
       "      <td>105.92</td>\n",
       "      <td>32.5</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60182</td>\n",
       "      <td>Female</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>171.23</td>\n",
       "      <td>34.4</td>\n",
       "      <td>smokes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1665</td>\n",
       "      <td>Female</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>Rural</td>\n",
       "      <td>174.12</td>\n",
       "      <td>24.0</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5105</th>\n",
       "      <td>18234</td>\n",
       "      <td>Female</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>83.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5106</th>\n",
       "      <td>44873</td>\n",
       "      <td>Female</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>Urban</td>\n",
       "      <td>125.20</td>\n",
       "      <td>40.0</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5107</th>\n",
       "      <td>19723</td>\n",
       "      <td>Female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>Rural</td>\n",
       "      <td>82.99</td>\n",
       "      <td>30.6</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5108</th>\n",
       "      <td>37544</td>\n",
       "      <td>Male</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Rural</td>\n",
       "      <td>166.29</td>\n",
       "      <td>25.6</td>\n",
       "      <td>formerly smoked</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5109</th>\n",
       "      <td>44679</td>\n",
       "      <td>Female</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Govt_job</td>\n",
       "      <td>Urban</td>\n",
       "      <td>85.28</td>\n",
       "      <td>26.2</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5110 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  gender   age  hypertension  heart_disease ever_married  \\\n",
       "0      9046    Male  67.0             0              1          Yes   \n",
       "1     51676  Female  61.0             0              0          Yes   \n",
       "2     31112    Male  80.0             0              1          Yes   \n",
       "3     60182  Female  49.0             0              0          Yes   \n",
       "4      1665  Female  79.0             1              0          Yes   \n",
       "...     ...     ...   ...           ...            ...          ...   \n",
       "5105  18234  Female  80.0             1              0          Yes   \n",
       "5106  44873  Female  81.0             0              0          Yes   \n",
       "5107  19723  Female  35.0             0              0          Yes   \n",
       "5108  37544    Male  51.0             0              0          Yes   \n",
       "5109  44679  Female  44.0             0              0          Yes   \n",
       "\n",
       "          work_type Residence_type  avg_glucose_level   bmi   smoking_status  \\\n",
       "0           Private          Urban             228.69  36.6  formerly smoked   \n",
       "1     Self-employed          Rural             202.21   NaN     never smoked   \n",
       "2           Private          Rural             105.92  32.5     never smoked   \n",
       "3           Private          Urban             171.23  34.4           smokes   \n",
       "4     Self-employed          Rural             174.12  24.0     never smoked   \n",
       "...             ...            ...                ...   ...              ...   \n",
       "5105        Private          Urban              83.75   NaN     never smoked   \n",
       "5106  Self-employed          Urban             125.20  40.0     never smoked   \n",
       "5107  Self-employed          Rural              82.99  30.6     never smoked   \n",
       "5108        Private          Rural             166.29  25.6  formerly smoked   \n",
       "5109       Govt_job          Urban              85.28  26.2          Unknown   \n",
       "\n",
       "      stroke  \n",
       "0          1  \n",
       "1          1  \n",
       "2          1  \n",
       "3          1  \n",
       "4          1  \n",
       "...      ...  \n",
       "5105       0  \n",
       "5106       0  \n",
       "5107       0  \n",
       "5108       0  \n",
       "5109       0  \n",
       "\n",
       "[5110 rows x 12 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strokes = pd.read_csv('datasets/healthcare-dataset-stroke-data.csv', dtype={'gender': 'category', 'age': float, 'hypertension': 'int8', 'heart_disease': 'int8', 'ever_married': 'category', 'work_type': 'category', 'Residence_type': 'category','avg_glucose_level': float, 'bmi': float, 'smoking_status': 'category', 'stroke': 'int8'})\n",
    "strokes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3936e4da",
   "metadata": {},
   "source": [
    "<p>Una vez importados los datos, se procede a comprobar si se han leído correctamente mediante el siguiente código. Además, Pandas mostrará información sobre el número de filas no nulas de cada atributo. Para que el conjunto de datos sea válido para entrenar un modelo, no deberá tener ningún valor nulo.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ddac8c6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5110 entries, 0 to 5109\n",
      "Data columns (total 12 columns):\n",
      " #   Column             Non-Null Count  Dtype   \n",
      "---  ------             --------------  -----   \n",
      " 0   id                 5110 non-null   int64   \n",
      " 1   gender             5110 non-null   category\n",
      " 2   age                5110 non-null   float64 \n",
      " 3   hypertension       5110 non-null   int8    \n",
      " 4   heart_disease      5110 non-null   int8    \n",
      " 5   ever_married       5110 non-null   category\n",
      " 6   work_type          5110 non-null   category\n",
      " 7   Residence_type     5110 non-null   category\n",
      " 8   avg_glucose_level  5110 non-null   float64 \n",
      " 9   bmi                4909 non-null   float64 \n",
      " 10  smoking_status     5110 non-null   category\n",
      " 11  stroke             5110 non-null   int8    \n",
      "dtypes: category(5), float64(3), int64(1), int8(3)\n",
      "memory usage: 200.5 KB\n"
     ]
    }
   ],
   "source": [
    "strokes.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3f4f3d",
   "metadata": {},
   "source": [
    "<p>Como se puede ver, el <i>dataset</i> tiene un total de 5110 entradas y 12 columnas. Todos los atributos tienen valor en la totalidad de las instancias, excepto la columna 9 (bmi), a la que le faltan 201 valores. Existen diferentes técnicas para solucionar este problema, tales como eliminar las filas que contengan los valores nulos, sustituirlos por un número concreto o rellenarlos con la media global de dicha propiedad. Para este caso, se ha considerado esta última solución como la más óptima. Para ello, será tan sencillo como ejecutar el siguiente código:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79dbad01",
   "metadata": {},
   "outputs": [],
   "source": [
    "strokes = strokes.fillna(strokes.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d18ba9",
   "metadata": {},
   "source": [
    "<p>Comprobamos que se hayan rellenado correctamente los valores nulos:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9488efe0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5110 entries, 0 to 5109\n",
      "Data columns (total 12 columns):\n",
      " #   Column             Non-Null Count  Dtype   \n",
      "---  ------             --------------  -----   \n",
      " 0   id                 5110 non-null   int64   \n",
      " 1   gender             5110 non-null   category\n",
      " 2   age                5110 non-null   float64 \n",
      " 3   hypertension       5110 non-null   int8    \n",
      " 4   heart_disease      5110 non-null   int8    \n",
      " 5   ever_married       5110 non-null   category\n",
      " 6   work_type          5110 non-null   category\n",
      " 7   Residence_type     5110 non-null   category\n",
      " 8   avg_glucose_level  5110 non-null   float64 \n",
      " 9   bmi                5110 non-null   float64 \n",
      " 10  smoking_status     5110 non-null   category\n",
      " 11  stroke             5110 non-null   int8    \n",
      "dtypes: category(5), float64(3), int64(1), int8(3)\n",
      "memory usage: 200.5 KB\n"
     ]
    }
   ],
   "source": [
    "strokes.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c8576f",
   "metadata": {},
   "source": [
    "<p>Además de no contener valores nulos, el <i>dataset</i> deberá ser tratado para convertir los valores de los atributos categóricos en números enteros, de forma que los algoritmos de aprendizaje puedan trabajar con ellos. Para hacer esto, seleccionaremos las columnas de tipo categoría y a cada una le aplicaremos la función <i>cat.codes</i>.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5ada948",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_columns = strokes.select_dtypes(['category']).columns\n",
    "strokes[cat_columns] = strokes[cat_columns].apply(lambda x: x.cat.codes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3185f421",
   "metadata": {},
   "source": [
    "<p>Como se puede ver, los tipos 'category' han pasado a ser enteros, habiéndose asignado a cada valor de la categoría un número:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40e3e71f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>ever_married</th>\n",
       "      <th>work_type</th>\n",
       "      <th>Residence_type</th>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>smoking_status</th>\n",
       "      <th>stroke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9046</td>\n",
       "      <td>1</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>228.69</td>\n",
       "      <td>36.600000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51676</td>\n",
       "      <td>0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>202.21</td>\n",
       "      <td>28.893237</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31112</td>\n",
       "      <td>1</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>105.92</td>\n",
       "      <td>32.500000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60182</td>\n",
       "      <td>0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>171.23</td>\n",
       "      <td>34.400000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1665</td>\n",
       "      <td>0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>174.12</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5105</th>\n",
       "      <td>18234</td>\n",
       "      <td>0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>83.75</td>\n",
       "      <td>28.893237</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5106</th>\n",
       "      <td>44873</td>\n",
       "      <td>0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>125.20</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5107</th>\n",
       "      <td>19723</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>82.99</td>\n",
       "      <td>30.600000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5108</th>\n",
       "      <td>37544</td>\n",
       "      <td>1</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>166.29</td>\n",
       "      <td>25.600000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5109</th>\n",
       "      <td>44679</td>\n",
       "      <td>0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>85.28</td>\n",
       "      <td>26.200000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5110 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  gender   age  hypertension  heart_disease  ever_married  \\\n",
       "0      9046       1  67.0             0              1             1   \n",
       "1     51676       0  61.0             0              0             1   \n",
       "2     31112       1  80.0             0              1             1   \n",
       "3     60182       0  49.0             0              0             1   \n",
       "4      1665       0  79.0             1              0             1   \n",
       "...     ...     ...   ...           ...            ...           ...   \n",
       "5105  18234       0  80.0             1              0             1   \n",
       "5106  44873       0  81.0             0              0             1   \n",
       "5107  19723       0  35.0             0              0             1   \n",
       "5108  37544       1  51.0             0              0             1   \n",
       "5109  44679       0  44.0             0              0             1   \n",
       "\n",
       "      work_type  Residence_type  avg_glucose_level        bmi  smoking_status  \\\n",
       "0             2               1             228.69  36.600000               1   \n",
       "1             3               0             202.21  28.893237               2   \n",
       "2             2               0             105.92  32.500000               2   \n",
       "3             2               1             171.23  34.400000               3   \n",
       "4             3               0             174.12  24.000000               2   \n",
       "...         ...             ...                ...        ...             ...   \n",
       "5105          2               1              83.75  28.893237               2   \n",
       "5106          3               1             125.20  40.000000               2   \n",
       "5107          3               0              82.99  30.600000               2   \n",
       "5108          2               0             166.29  25.600000               1   \n",
       "5109          0               1              85.28  26.200000               0   \n",
       "\n",
       "      stroke  \n",
       "0          1  \n",
       "1          1  \n",
       "2          1  \n",
       "3          1  \n",
       "4          1  \n",
       "...      ...  \n",
       "5105       0  \n",
       "5106       0  \n",
       "5107       0  \n",
       "5108       0  \n",
       "5109       0  \n",
       "\n",
       "[5110 rows x 12 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strokes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd67494c",
   "metadata": {},
   "source": [
    "<p>Una vez preparado el <i>dataset</i>, se puede proceder a construir el <i>dataframe</i> que contenga las características de las que extraer la información y el que almacene la variable objetivo, en este caso el atributo binario 'stroke', el cual determinará si el paciente es propenso a sufrir una isquemia cerebral o no. Para ello, del <i>dataframe</i> completo se han eliminado las columnas 'id' (puesto que no aporta información) y 'stroke' (ya que es la variable objetivo) para construir el de características, y se ha incluido únicamente la columna 'stroke' para crear el <i>dataframe</i> objetivo.</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "440d82fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = strokes.drop(['stroke', 'id'], axis=1)\n",
    "target = strokes['stroke']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f038f8",
   "metadata": {},
   "source": [
    "<p>El contenido y la estructura de los <i>dataframes</i> son las siguientes:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5298c9d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>ever_married</th>\n",
       "      <th>work_type</th>\n",
       "      <th>Residence_type</th>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>smoking_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>228.69</td>\n",
       "      <td>36.600000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>202.21</td>\n",
       "      <td>28.893237</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>105.92</td>\n",
       "      <td>32.500000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>171.23</td>\n",
       "      <td>34.400000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>174.12</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5105</th>\n",
       "      <td>0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>83.75</td>\n",
       "      <td>28.893237</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5106</th>\n",
       "      <td>0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>125.20</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5107</th>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>82.99</td>\n",
       "      <td>30.600000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5108</th>\n",
       "      <td>1</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>166.29</td>\n",
       "      <td>25.600000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5109</th>\n",
       "      <td>0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>85.28</td>\n",
       "      <td>26.200000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5110 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      gender   age  hypertension  heart_disease  ever_married  work_type  \\\n",
       "0          1  67.0             0              1             1          2   \n",
       "1          0  61.0             0              0             1          3   \n",
       "2          1  80.0             0              1             1          2   \n",
       "3          0  49.0             0              0             1          2   \n",
       "4          0  79.0             1              0             1          3   \n",
       "...      ...   ...           ...            ...           ...        ...   \n",
       "5105       0  80.0             1              0             1          2   \n",
       "5106       0  81.0             0              0             1          3   \n",
       "5107       0  35.0             0              0             1          3   \n",
       "5108       1  51.0             0              0             1          2   \n",
       "5109       0  44.0             0              0             1          0   \n",
       "\n",
       "      Residence_type  avg_glucose_level        bmi  smoking_status  \n",
       "0                  1             228.69  36.600000               1  \n",
       "1                  0             202.21  28.893237               2  \n",
       "2                  0             105.92  32.500000               2  \n",
       "3                  1             171.23  34.400000               3  \n",
       "4                  0             174.12  24.000000               2  \n",
       "...              ...                ...        ...             ...  \n",
       "5105               1              83.75  28.893237               2  \n",
       "5106               1             125.20  40.000000               2  \n",
       "5107               0              82.99  30.600000               2  \n",
       "5108               0             166.29  25.600000               1  \n",
       "5109               1              85.28  26.200000               0  \n",
       "\n",
       "[5110 rows x 10 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "243d7779",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1       1\n",
       "2       1\n",
       "3       1\n",
       "4       1\n",
       "       ..\n",
       "5105    0\n",
       "5106    0\n",
       "5107    0\n",
       "5108    0\n",
       "5109    0\n",
       "Name: stroke, Length: 5110, dtype: int8"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3fe6087",
   "metadata": {},
   "source": [
    "<p>Otro aspecto muy importante a valorar del <i>dataset</i> es su gran desequilibrio entre los casos con accidente cerebrovascular y los pacientes no propensos a él. Como se puede ver, de 5110 casos, solo 249 son positivos. Esto provocará que si utilizamos como método de evaluación del aprendizaje una métrica como la precisión, un predictor trivial que siempre devuelva 0 (no propenso) tendrá una precisión de más del 95% con este <i>dataset</i>. Por tanto, se deberá utilizar otra métrica para evaluar la calidad del modelo de aprendizaje.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b1abbdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4861\n",
       "1     249\n",
       "Name: stroke, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5cb0a82",
   "metadata": {},
   "source": [
    "<p>De todas las métricas posibles para evaluar modelos, se ha escogido la ROC AUC, ya que esta valora que se predigan correctamente tanto los casos positivos como los negativos, pudiendo llegar únicamente al 0,5 de precisión si se predicen sólo los casos negativos, de modo que un predictor trivial tendría un mal rendimiento. De esta manera, se premiará al modelo si es capaz también de 'aprender' y predecir los casos positivos de isquemia, aunque estos sean la minoría.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019e0b06",
   "metadata": {},
   "source": [
    "<p>Como último paso previo al comienzo del entrenamiento, se deberán dividir los <i>dataframes</i> de características y el objetivo en dos partes cada uno, de manera que se tengan datos para el aprendizaje (en este caso serán el 75% de ellos) y para la prueba de precisión (el 25%)</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a9086776",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_features, testing_features, training_target, testing_target = \\\n",
    "            train_test_split(features, target, train_size=0.75, test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84bf83c",
   "metadata": {},
   "source": [
    "<h2>2. Declaración del clasificador de aprendizaje automático automatizado y búsqueda del mejor modelo</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a77eeeb",
   "metadata": {},
   "source": [
    "<p>La búsqueda del mejor modelo se hará utilizando el método StructuredDataClassifier, al cual se le pasa por parámetro:\n",
    "<ul>\n",
    "    <li>Las ejecuciones máximas, en este caso 20.</li>\n",
    "    <li>El objetivo relacionado con la métrica elegida y cuya dirección será maximizar</li>\n",
    "    <li>La métrica de puntuaje elegida (AUC)</li>\n",
    "    <li>El tuner que utilizará el algoritmo. Por defecto utiliza 'greedy', el cual aborta la ejecución a los pocos minutos de iniciarse, al parecer por un error. Por ello, se utilizará otro distinto, en este caso 'bayesian'.</li>\n",
    "    <li>El nombre del proyecto, en el cual se guardarán los modelos calculados</li>\n",
    "</ul>\n",
    "\n",
    "Se parará tras 3200 iteraciones de 250 <i>epochs</i> máximas o tras aproximadamente 24 horas. AutoKeras hará uso de la totalidad de núcleos del procesador de forma predeterminada, por lo que no hará falta indicarle ningún parámetro para ello.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6a5ebc48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project ./autokeras_stroke/oracle.json\n",
      "INFO:tensorflow:Reloading Tuner from ./autokeras_stroke/tuner0.json\n"
     ]
    }
   ],
   "source": [
    "AUC_obj = kt.Objective('val_AUC', direction='max')\n",
    "AUC_metric = tf.keras.metrics.AUC(name='AUC')\n",
    "clf = ak.StructuredDataClassifier(max_trials=1, objective=AUC_obj, metrics=[AUC_metric], tuner='bayesian', project_name='autokeras_stroke')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b09292",
   "metadata": {},
   "source": [
    "<p>Se ejecuta el método <i>fit</i> para iniciar la búsqueda del mejor modelo clasificador. Debido a que AutoKeras no ofrece ninguna manera de finalizar el entrenamiento tras un cierto tiempo, se ha parado manualmente tras 25 horas y 34 minutos, habiéndose realizando con éxito 2.540 <i>trials</i> de un máximo de 250 <i>epochs</i> sobre el <i>dataset</i>, consiguiendo una precisión AUC del 0.7761 sobre el conjunto de entrenamiento. Para que AutoKeras construya la mejor <i>pipeline</i> y muestre el rendimiento del predictor, se ha ejecutado un entrenamiento de 1 solo <i>trial</i> sobre los datos guardados (ya que AutoKeras va almacenando en disco todo el proceso de entrenamiento). Esto es necesario ya que al parar manualmente el proceso de entrenamiento AutoKeras aborta inmediatamente, sin construir los resultados. Tras finalizar esa ronda, AutoKeras ha construido la mejor <i>pipeline</i> de todo el entrenamiento completo y ya es posible consultar los resultados. Toda la información de cada <i>trial</i> se encuentra en la carpeta del proyecto 'autokeras_stroke'.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2043048c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Oracle triggered exit\n",
      "Epoch 1/250\n",
      "120/120 [==============================] - 1s 1ms/step - loss: 0.4951 - AUC: 0.4550\n",
      "Epoch 2/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.2333 - AUC: 0.6071\n",
      "Epoch 3/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.2107 - AUC: 0.6565\n",
      "Epoch 4/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1962 - AUC: 0.6872\n",
      "Epoch 5/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1917 - AUC: 0.6992\n",
      "Epoch 6/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1869 - AUC: 0.7125\n",
      "Epoch 7/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1839 - AUC: 0.7209\n",
      "Epoch 8/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1817 - AUC: 0.7264\n",
      "Epoch 9/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1807 - AUC: 0.7225\n",
      "Epoch 10/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1832 - AUC: 0.7129\n",
      "Epoch 11/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1820 - AUC: 0.7239\n",
      "Epoch 12/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1835 - AUC: 0.7071\n",
      "Epoch 13/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1798 - AUC: 0.7271\n",
      "Epoch 14/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1861 - AUC: 0.6998\n",
      "Epoch 15/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1841 - AUC: 0.7046\n",
      "Epoch 16/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1845 - AUC: 0.6961\n",
      "Epoch 17/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1856 - AUC: 0.6709\n",
      "Epoch 18/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1841 - AUC: 0.6913\n",
      "Epoch 19/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1862 - AUC: 0.6680\n",
      "Epoch 20/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1822 - AUC: 0.6933\n",
      "Epoch 21/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1862 - AUC: 0.6798\n",
      "Epoch 22/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1900 - AUC: 0.6588\n",
      "Epoch 23/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1854 - AUC: 0.6670\n",
      "Epoch 24/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1874 - AUC: 0.6491\n",
      "Epoch 25/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1921 - AUC: 0.6364\n",
      "Epoch 26/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1960 - AUC: 0.6295\n",
      "Epoch 27/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1884 - AUC: 0.6352\n",
      "Epoch 28/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1882 - AUC: 0.6199\n",
      "Epoch 29/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1883 - AUC: 0.6206\n",
      "Epoch 30/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1887 - AUC: 0.5962\n",
      "Epoch 31/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1874 - AUC: 0.6159\n",
      "Epoch 32/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1868 - AUC: 0.6144\n",
      "Epoch 33/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1881 - AUC: 0.6362\n",
      "Epoch 34/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1856 - AUC: 0.6431\n",
      "Epoch 35/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1880 - AUC: 0.6241\n",
      "Epoch 36/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1917 - AUC: 0.6249\n",
      "Epoch 37/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1862 - AUC: 0.6297\n",
      "Epoch 38/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1853 - AUC: 0.6463\n",
      "Epoch 39/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1873 - AUC: 0.6245\n",
      "Epoch 40/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1876 - AUC: 0.6140\n",
      "Epoch 41/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1862 - AUC: 0.6094\n",
      "Epoch 42/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1857 - AUC: 0.6312\n",
      "Epoch 43/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1848 - AUC: 0.6349\n",
      "Epoch 44/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1879 - AUC: 0.6207\n",
      "Epoch 45/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1888 - AUC: 0.6064\n",
      "Epoch 46/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1851 - AUC: 0.6155\n",
      "Epoch 47/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1896 - AUC: 0.6006\n",
      "Epoch 48/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1861 - AUC: 0.6017\n",
      "Epoch 49/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1866 - AUC: 0.6214\n",
      "Epoch 50/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1860 - AUC: 0.6192\n",
      "Epoch 51/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1859 - AUC: 0.6253\n",
      "Epoch 52/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1878 - AUC: 0.6241\n",
      "Epoch 53/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1883 - AUC: 0.5985\n",
      "Epoch 54/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1878 - AUC: 0.6100\n",
      "Epoch 55/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1854 - AUC: 0.6208\n",
      "Epoch 56/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1847 - AUC: 0.6309\n",
      "Epoch 57/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1856 - AUC: 0.6341\n",
      "Epoch 58/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1868 - AUC: 0.6147\n",
      "Epoch 59/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1834 - AUC: 0.6155\n",
      "Epoch 60/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1825 - AUC: 0.6493\n",
      "Epoch 61/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1886 - AUC: 0.6316\n",
      "Epoch 62/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1859 - AUC: 0.6152\n",
      "Epoch 63/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1852 - AUC: 0.6194\n",
      "Epoch 64/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1855 - AUC: 0.6190\n",
      "Epoch 65/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1860 - AUC: 0.6139\n",
      "Epoch 66/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1847 - AUC: 0.6334\n",
      "Epoch 67/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1841 - AUC: 0.6157\n",
      "Epoch 68/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1846 - AUC: 0.6271\n",
      "Epoch 69/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1889 - AUC: 0.6107\n",
      "Epoch 70/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1853 - AUC: 0.6128\n",
      "Epoch 71/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1864 - AUC: 0.6158\n",
      "Epoch 72/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1863 - AUC: 0.6123\n",
      "Epoch 73/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1862 - AUC: 0.6180\n",
      "Epoch 74/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1853 - AUC: 0.6193\n",
      "Epoch 75/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1852 - AUC: 0.6285\n",
      "Epoch 76/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1864 - AUC: 0.6234\n",
      "Epoch 77/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1868 - AUC: 0.6086\n",
      "Epoch 78/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1863 - AUC: 0.6252\n",
      "Epoch 79/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1864 - AUC: 0.6201\n",
      "Epoch 80/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1856 - AUC: 0.6141\n",
      "Epoch 81/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1834 - AUC: 0.6252\n",
      "Epoch 82/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1859 - AUC: 0.6268\n",
      "Epoch 83/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1829 - AUC: 0.6449\n",
      "Epoch 84/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1871 - AUC: 0.6169\n",
      "Epoch 85/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1866 - AUC: 0.6119\n",
      "Epoch 86/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1845 - AUC: 0.6265\n",
      "Epoch 87/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1846 - AUC: 0.6174\n",
      "Epoch 88/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1831 - AUC: 0.6306\n",
      "Epoch 89/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1883 - AUC: 0.6037\n",
      "Epoch 90/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1869 - AUC: 0.6011\n",
      "Epoch 91/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1831 - AUC: 0.6278\n",
      "Epoch 92/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1867 - AUC: 0.6170\n",
      "Epoch 93/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1884 - AUC: 0.6165\n",
      "Epoch 94/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1854 - AUC: 0.6125\n",
      "Epoch 95/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1857 - AUC: 0.6167\n",
      "Epoch 96/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1860 - AUC: 0.6162\n",
      "Epoch 97/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1871 - AUC: 0.6109\n",
      "Epoch 98/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1864 - AUC: 0.6149\n",
      "Epoch 99/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1879 - AUC: 0.6046\n",
      "Epoch 100/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1863 - AUC: 0.6063\n",
      "Epoch 101/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1846 - AUC: 0.6185\n",
      "Epoch 102/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1870 - AUC: 0.6115\n",
      "Epoch 103/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1848 - AUC: 0.6201\n",
      "Epoch 104/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1867 - AUC: 0.6206\n",
      "Epoch 105/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1851 - AUC: 0.6193\n",
      "Epoch 106/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1842 - AUC: 0.6264\n",
      "Epoch 107/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1871 - AUC: 0.6174\n",
      "Epoch 108/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1847 - AUC: 0.6200\n",
      "Epoch 109/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1845 - AUC: 0.6282\n",
      "Epoch 110/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1851 - AUC: 0.6225\n",
      "Epoch 111/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1853 - AUC: 0.6170\n",
      "Epoch 112/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1868 - AUC: 0.6196\n",
      "Epoch 113/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1859 - AUC: 0.6231\n",
      "Epoch 114/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1839 - AUC: 0.6214\n",
      "Epoch 115/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1842 - AUC: 0.6281\n",
      "Epoch 116/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1843 - AUC: 0.6265\n",
      "Epoch 117/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1839 - AUC: 0.6266\n",
      "Epoch 118/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1850 - AUC: 0.6268\n",
      "Epoch 119/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1870 - AUC: 0.6106\n",
      "Epoch 120/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1855 - AUC: 0.6216\n",
      "Epoch 121/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1867 - AUC: 0.6189\n",
      "Epoch 122/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1860 - AUC: 0.6238\n",
      "Epoch 123/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1848 - AUC: 0.6326\n",
      "Epoch 124/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1835 - AUC: 0.6361\n",
      "Epoch 125/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1867 - AUC: 0.6192\n",
      "Epoch 126/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1851 - AUC: 0.6219\n",
      "Epoch 127/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1846 - AUC: 0.6184\n",
      "Epoch 128/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1850 - AUC: 0.6209\n",
      "Epoch 129/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1856 - AUC: 0.6229\n",
      "Epoch 130/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1851 - AUC: 0.6216\n",
      "Epoch 131/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1837 - AUC: 0.6173\n",
      "Epoch 132/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1844 - AUC: 0.6361\n",
      "Epoch 133/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1844 - AUC: 0.6326\n",
      "Epoch 134/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1840 - AUC: 0.6346\n",
      "Epoch 135/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1826 - AUC: 0.6306\n",
      "Epoch 136/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1827 - AUC: 0.6376\n",
      "Epoch 137/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1838 - AUC: 0.6298\n",
      "Epoch 138/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1881 - AUC: 0.6149\n",
      "Epoch 139/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1852 - AUC: 0.6172\n",
      "Epoch 140/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1846 - AUC: 0.6193\n",
      "Epoch 141/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1858 - AUC: 0.6147\n",
      "Epoch 142/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1841 - AUC: 0.6346\n",
      "Epoch 143/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1841 - AUC: 0.6332\n",
      "Epoch 144/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1845 - AUC: 0.6268\n",
      "Epoch 145/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1842 - AUC: 0.6245\n",
      "Epoch 146/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1854 - AUC: 0.6334\n",
      "Epoch 147/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1832 - AUC: 0.6316\n",
      "Epoch 148/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1847 - AUC: 0.6299\n",
      "Epoch 149/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1847 - AUC: 0.6230\n",
      "Epoch 150/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1831 - AUC: 0.6286\n",
      "Epoch 151/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1846 - AUC: 0.6189\n",
      "Epoch 152/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1847 - AUC: 0.6327\n",
      "Epoch 153/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1841 - AUC: 0.6496\n",
      "Epoch 154/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1846 - AUC: 0.6506\n",
      "Epoch 155/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1841 - AUC: 0.6501\n",
      "Epoch 156/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1839 - AUC: 0.6493\n",
      "Epoch 157/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1847 - AUC: 0.6351\n",
      "Epoch 158/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1798 - AUC: 0.6736\n",
      "Epoch 159/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1833 - AUC: 0.6686\n",
      "Epoch 160/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1835 - AUC: 0.6429\n",
      "Epoch 161/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1836 - AUC: 0.6482\n",
      "Epoch 162/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1842 - AUC: 0.6533\n",
      "Epoch 163/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1804 - AUC: 0.6765\n",
      "Epoch 164/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1842 - AUC: 0.6443\n",
      "Epoch 165/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1823 - AUC: 0.6619\n",
      "Epoch 166/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1835 - AUC: 0.6568\n",
      "Epoch 167/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1822 - AUC: 0.6556\n",
      "Epoch 168/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1833 - AUC: 0.6623\n",
      "Epoch 169/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1812 - AUC: 0.6690\n",
      "Epoch 170/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1830 - AUC: 0.6535\n",
      "Epoch 171/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1801 - AUC: 0.6737\n",
      "Epoch 172/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1805 - AUC: 0.6801\n",
      "Epoch 173/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1829 - AUC: 0.6728\n",
      "Epoch 174/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1828 - AUC: 0.6736\n",
      "Epoch 175/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1829 - AUC: 0.6719\n",
      "Epoch 176/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1800 - AUC: 0.6814\n",
      "Epoch 177/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1836 - AUC: 0.6672\n",
      "Epoch 178/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1828 - AUC: 0.6597\n",
      "Epoch 179/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1818 - AUC: 0.6762\n",
      "Epoch 180/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1833 - AUC: 0.6601\n",
      "Epoch 181/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1808 - AUC: 0.6829\n",
      "Epoch 182/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1831 - AUC: 0.6593\n",
      "Epoch 183/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1823 - AUC: 0.6751\n",
      "Epoch 184/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1832 - AUC: 0.6611\n",
      "Epoch 185/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1822 - AUC: 0.6770\n",
      "Epoch 186/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1814 - AUC: 0.6722\n",
      "Epoch 187/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1806 - AUC: 0.6820\n",
      "Epoch 188/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1798 - AUC: 0.6919\n",
      "Epoch 189/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1824 - AUC: 0.6619\n",
      "Epoch 190/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1797 - AUC: 0.6977\n",
      "Epoch 191/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1829 - AUC: 0.6727\n",
      "Epoch 192/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1819 - AUC: 0.6738\n",
      "Epoch 193/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1824 - AUC: 0.6738\n",
      "Epoch 194/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1816 - AUC: 0.6825\n",
      "Epoch 195/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1815 - AUC: 0.6801\n",
      "Epoch 196/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1823 - AUC: 0.6727\n",
      "Epoch 197/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1798 - AUC: 0.6924\n",
      "Epoch 198/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1834 - AUC: 0.6695\n",
      "Epoch 199/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1818 - AUC: 0.6729\n",
      "Epoch 200/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1805 - AUC: 0.6836\n",
      "Epoch 201/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1806 - AUC: 0.6825\n",
      "Epoch 202/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1793 - AUC: 0.6993\n",
      "Epoch 203/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1801 - AUC: 0.6816\n",
      "Epoch 204/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1802 - AUC: 0.6786\n",
      "Epoch 205/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1787 - AUC: 0.6967\n",
      "Epoch 206/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1810 - AUC: 0.6744\n",
      "Epoch 207/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1811 - AUC: 0.6725\n",
      "Epoch 208/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1788 - AUC: 0.7004\n",
      "Epoch 209/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1791 - AUC: 0.6949\n",
      "Epoch 210/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1802 - AUC: 0.6875\n",
      "Epoch 211/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1808 - AUC: 0.6836\n",
      "Epoch 212/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1777 - AUC: 0.6964\n",
      "Epoch 213/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1817 - AUC: 0.6818\n",
      "Epoch 214/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1795 - AUC: 0.6934\n",
      "Epoch 215/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1799 - AUC: 0.6764\n",
      "Epoch 216/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1775 - AUC: 0.7006\n",
      "Epoch 217/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1808 - AUC: 0.6874\n",
      "Epoch 218/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1805 - AUC: 0.6804\n",
      "Epoch 219/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1792 - AUC: 0.6912\n",
      "Epoch 220/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1805 - AUC: 0.6835\n",
      "Epoch 221/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1817 - AUC: 0.6758\n",
      "Epoch 222/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1801 - AUC: 0.6863\n",
      "Epoch 223/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1780 - AUC: 0.7070\n",
      "Epoch 224/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1792 - AUC: 0.6862\n",
      "Epoch 225/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1792 - AUC: 0.6923\n",
      "Epoch 226/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1795 - AUC: 0.6975\n",
      "Epoch 227/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1794 - AUC: 0.6936\n",
      "Epoch 228/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1805 - AUC: 0.6897\n",
      "Epoch 229/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1795 - AUC: 0.6886\n",
      "Epoch 230/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1798 - AUC: 0.6959\n",
      "Epoch 231/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1783 - AUC: 0.6918\n",
      "Epoch 232/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1786 - AUC: 0.6985\n",
      "Epoch 233/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1777 - AUC: 0.7042\n",
      "Epoch 234/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1776 - AUC: 0.7106\n",
      "Epoch 235/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1783 - AUC: 0.6959\n",
      "Epoch 236/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1782 - AUC: 0.7045\n",
      "Epoch 237/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1783 - AUC: 0.7090\n",
      "Epoch 238/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1776 - AUC: 0.7091\n",
      "Epoch 239/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1787 - AUC: 0.7023\n",
      "Epoch 240/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1775 - AUC: 0.7155\n",
      "Epoch 241/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1780 - AUC: 0.7148\n",
      "Epoch 242/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1780 - AUC: 0.7078\n",
      "Epoch 243/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1764 - AUC: 0.7227\n",
      "Epoch 244/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1758 - AUC: 0.7199\n",
      "Epoch 245/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1782 - AUC: 0.7060\n",
      "Epoch 246/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1761 - AUC: 0.7267\n",
      "Epoch 247/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1758 - AUC: 0.7213\n",
      "Epoch 248/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1765 - AUC: 0.7161\n",
      "Epoch 249/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1757 - AUC: 0.7264\n",
      "Epoch 250/250\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1758 - AUC: 0.7283\n",
      "INFO:tensorflow:Assets written to: ./autokeras_stroke/best_model/assets\n"
     ]
    }
   ],
   "source": [
    "clf.fit(training_features, training_target, epochs = 250)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85437252",
   "metadata": {},
   "source": [
    "<p>Una vez finalizada la búsqueda, se muestra la precisión del mejor modelo siguiendo la métrica AUC:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a467dfcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1849 - AUC: 0.7123\n",
      "[0.18486236035823822, 0.7123103141784668]\n"
     ]
    }
   ],
   "source": [
    "print(clf.evaluate(testing_features, testing_target))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb3d101",
   "metadata": {},
   "source": [
    "<p>Y se exporta a un archivo externo:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cd9cb1f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.functional.Functional at 0x7f1d78caefd0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.export_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
